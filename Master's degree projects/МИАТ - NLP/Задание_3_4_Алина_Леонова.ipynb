{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ojCqutxyZeUP"
   },
   "source": [
    "## Лабораторная работа №3. Коррекция опечаток\n",
    "#### Предмет: Методы интеллектуального анализа текстов\n",
    "#### Студент: Леонова Алина, СБ № 1032212306, НФИмд-01-21"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tlrYWT0yhBLU"
   },
   "source": [
    "### 3.4.\tНаписать функцию сравнения векторов, составленных из частотностей входящих в слово букв (CountVectorizer). Помимо верных вариантов слов из примеров использовать в небольшом словаре своего метода дополнительно похожие и непохожие на верные слова русского языка.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "Bu069Y1VTwM7"
   },
   "outputs": [],
   "source": [
    "examples = [\"вот в инете откапал такую инеерсную статейку предлагаю вашему внимани\",\n",
    "            \"может и в правду лутше тебе молчать чем пытаться сказать\",\n",
    "            \"утром мы сидели как сычи а потом каааак начали работать\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "MDKxfXUogvoz"
   },
   "outputs": [],
   "source": [
    "# частотный словарь для русского языка\n",
    "! wget -q https://github.com/Baksalyar/mc.hertzbeat.ru-Frequency-Dictionaries/raw/master/mc.hertzbeat.ru_frequency_dict.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "knYIMlfqB9Y-",
    "outputId": "00498d72-079c-47e4-8c17-c41fa76f8e8a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1042"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# правильные слова для данного примера и другие существующие слова, близкие к ним\n",
    "w = ['вот','в','инете','откопал','такую','интересную','статейку','предлагаю','вашему','вниманию','может','и','вправду','лучше','тебе','молчать','чем','пытаться','сказать','утром','мы','сидели','как','сычи','а','потом','как','начали','работать']\n",
    "other_w = ['копал','капал','такая','интересно','возлогаю','внимание','тобой','молчишь','правда','сказка','после','потел','потемки']\n",
    "\n",
    "freq_dict = []\n",
    "with open(\"mc.hertzbeat.ru_frequency_dict.txt\", \"r\") as f:\n",
    "    for string in f:\n",
    "        freq_dict.append(string.split()[0])   # только сами слова, без частот\n",
    "\n",
    "# объединение нужных для примера слов, других существующих слов, близких к ним, и 1000 самых частотных слов\n",
    "n_freq = 1000   # в словаре самых частотных слов 480092 слова, можно увеличить их количество, что, возможно, улучшит качество работы и уменьшит скорость\n",
    "w_dict = w + other_w + freq_dict[:n_freq]\n",
    "\n",
    "len(w_dict)   # размер итогового списка эталонных слов для сравнения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e6L0XrnUFT3-",
    "outputId": "93970556-7672-4261-c627-1c2dd2260500"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "вот вот 1.0\n",
      "в в 1.0\n",
      "инете инете 1.0\n",
      "*  откапал капал 0.856349\n",
      "такую такую 1.0\n",
      "*  инеерсную интересную 0.819028\n",
      "статейку статейку 1.0\n",
      "предлагаю предлагаю 1.0\n",
      "вашему вашему 1.0\n",
      "*  внимани вниманию 0.95119\n",
      "\n",
      "может может 1.0\n",
      "и и 1.0\n",
      "в в 1.0\n",
      "*  правду вправду 0.934199\n",
      "*  лутше лучше 0.666667\n",
      "тебе тебе 1.0\n",
      "молчать молчать 1.0\n",
      "чем чем 1.0\n",
      "пытаться пытаться 1.0\n",
      "сказать сказать 1.0\n",
      "\n",
      "утром утром 1.0\n",
      "мы мы 1.0\n",
      "сидели сидели 1.0\n",
      "как как 1.0\n",
      "сычи сычи 1.0\n",
      "а а 1.0\n",
      "потом потом 1.0\n",
      "*  каааак а 0.718421\n",
      "начали начали 1.0\n",
      "работать работать 1.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import RegexpTokenizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy.linalg import norm\n",
    "# from sklearn.metrics.pairwise import cosine_similarity,cosine_distances\n",
    "\n",
    "\n",
    "def check_vectors(tokens, dict_w):\n",
    "  # нахождение букв и биграм проверяемого слова\n",
    "  # нахождение косинусной близости проверяемого слова со словами из словаря\n",
    "  for t in tokens:\n",
    "    best_sim = 0\n",
    "    for w in dict_w:\n",
    "      cv =  CountVectorizer(analyzer=\"char\", ngram_range=(1,2))\n",
    "      count_matrix = cv.fit_transform([t, w])\n",
    "      count_array = count_matrix.toarray()\n",
    "      df = pd.DataFrame(data=count_array,columns = cv.get_feature_names_out())\n",
    "      #print(df)     # печать векторов для пары сравниваемых слов\n",
    "      \n",
    "      v_t = np.array(df.loc[0])\n",
    "      v_w = np.array(df.loc[1])\n",
    "      \n",
    "      # косинусная близость\n",
    "      cos_sim = round( np.dot(v_t, v_w)/(norm(v_t)*norm(v_w)) , 6)    # результаты совпадают с работой библиотечной\n",
    "      #cos_sim = round(cosine_similarity(v_t.reshape(1,-1), v_w.reshape(1,-1))[0][0], 6)\n",
    "\n",
    "\n",
    "      if cos_sim == 1:\n",
    "        best_sim = cos_sim\n",
    "        print(t, w, best_sim)\n",
    "        break\n",
    "      elif cos_sim > best_sim:   # запоминание наибольшей близости и слова\n",
    "        best_sim = cos_sim\n",
    "        best_word = w\n",
    "\n",
    "    if best_sim != 1:\n",
    "      print('* ', t, best_word, best_sim)\n",
    "\n",
    "\n",
    "# тестирование\n",
    "for row in examples:\n",
    "  tokenizer=RegexpTokenizer('\\W+', gaps=True)     \n",
    "  t = tokenizer.tokenize(row)\n",
    "  check_vectors(t, w_dict)\n",
    "  print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0QAkxIiyNiIr"
   },
   "source": [
    "Успешность работы зависит от словаря. Для ошибочного слова 'откапал' было добавлено правильное по контексту 'откопал' и ошибочное тут 'капал', но векторно второе оказалось ближе к первоначальному.\n",
    "\n",
    "А также метод не поможет с большым количеством лишних букв, наиближайшим словом к 'каааак' оказалось 'а'."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
